{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steelers Games Summary Data Scrape\n",
    "\n",
    "[pro-football reference](https://www.pro-football-reference.com/) Pro-football reference includes NFL data, dating back to 1967. This data includes player statistics, all-time leaders, draft history, coaches, and much more. Statistics are updated by every week, no later than Tuesday at 6pm. Additional data can be found behind a paid subscription.\n",
    "\n",
    "*this overview comes from [Ohio State's Sports and Society Initiative](https://sportsandsociety.osu.edu/sports-data-sets)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import lxml # used for parsing html\n",
    "\n",
    "# bigquery\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery\n",
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "import db_dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for the Steelers' main page\n",
    "base_url = \"https://www.pro-football-reference.com/teams/pit/\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "# Step 1: Scrape the main page to get links for each year\n",
    "response = requests.get(base_url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# check for successful request\n",
    "if response.status_code != 200:\n",
    "    print(\"Failed to retrieve the page\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no Failure message we are good to continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all year links from the main team page\n",
    "year_links_start = [\n",
    "    base_url + a['href']\n",
    "    for a in soup.select('table#team_index a[href]')\n",
    "    if re.match(r'/teams/pit/\\d{4}\\.htm', a['href'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.pro-football-reference.com/teams/pit/2024.htm',\n",
       " 'https://www.pro-football-reference.com/teams/pit/2023.htm',\n",
       " 'https://www.pro-football-reference.com/teams/pit/2022.htm',\n",
       " 'https://www.pro-football-reference.com/teams/pit/2021.htm',\n",
       " 'https://www.pro-football-reference.com/teams/pit/2020.htm']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to remove duplicates and preserve the order\n",
    "\n",
    "def removeduplicate(data):\n",
    "    countdict = {}\n",
    "    for element in data:\n",
    "        if element in countdict.keys():\n",
    "            \n",
    "            # increasing the count if the key(or element)\n",
    "            # is already in the dictionary\n",
    "            countdict[element] += 1\n",
    "        else:\n",
    "            # inserting the element as key  with count = 1\n",
    "            countdict[element] = 1\n",
    "    data.clear()\n",
    "    for key in countdict.keys():\n",
    "        data.append(key)\n",
    "        \n",
    "removeduplicate(year_links_start)\n",
    "\n",
    "# remove //teams/pit from the urls\n",
    "year_links = [link.replace(\"//teams/pit\", \"\") for link in year_links_start]\n",
    "\n",
    "year_links[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for year 2024...\n",
      "Scraping data for year 2023...\n",
      "Scraping data for year 2022...\n",
      "Scraping data for year 2021...\n",
      "Scraping data for year 2020...\n",
      "Scraping data for year 2019...\n",
      "Scraping data for year 2018...\n",
      "Scraping data for year 2017...\n",
      "Scraping data for year 2016...\n",
      "Scraping data for year 2015...\n",
      "Scraping data for year 2014...\n",
      "Scraping data for year 2013...\n",
      "Scraping data for year 2012...\n",
      "Scraping data for year 2011...\n",
      "Scraping data for year 2010...\n",
      "Scraping data for year 2009...\n",
      "Scraping data for year 2008...\n",
      "Scraping data for year 2007...\n",
      "Scraping data for year 2006...\n",
      "Scraping data for year 2005...\n",
      "Scraping data for year 2004...\n",
      "Scraping data for year 2003...\n",
      "Scraping data for year 2002...\n",
      "Scraping data for year 2001...\n",
      "Scraping data for year 2000...\n",
      "Scraping data for year 1999...\n",
      "Scraping data for year 1998...\n",
      "Scraping data for year 1997...\n",
      "Scraping data for year 1996...\n",
      "Scraping data for year 1995...\n",
      "Scraping data for year 1994...\n",
      "Scraping data for year 1993...\n",
      "Scraping data for year 1992...\n",
      "Scraping data for year 1991...\n",
      "Scraping data for year 1990...\n",
      "Scraping data for year 1989...\n",
      "Scraping data for year 1988...\n",
      "Scraping data for year 1987...\n",
      "Scraping data for year 1986...\n",
      "Scraping data for year 1985...\n",
      "Scraping data for year 1984...\n",
      "Scraping data for year 1983...\n",
      "Scraping data for year 1982...\n",
      "Scraping data for year 1981...\n",
      "Scraping data for year 1980...\n",
      "Scraping data for year 1979...\n",
      "Scraping data for year 1978...\n",
      "Scraping data for year 1977...\n",
      "Scraping data for year 1976...\n",
      "Scraping data for year 1975...\n",
      "Scraping data for year 1974...\n",
      "Scraping data for year 1973...\n",
      "Scraping data for year 1972...\n",
      "Scraping data for year 1971...\n",
      "Scraping data for year 1970...\n",
      "Scraping data for year 1969...\n",
      "Scraping data for year 1968...\n",
      "Scraping data for year 1967...\n",
      "Scraping data for year 1966...\n",
      "Scraping data for year 1965...\n",
      "Scraping data for year 1964...\n",
      "Scraping data for year 1963...\n",
      "Scraping data for year 1962...\n",
      "Scraping data for year 1961...\n",
      "Scraping data for year 1960...\n",
      "Scraping data for year 1959...\n",
      "Scraping data for year 1958...\n",
      "Scraping data for year 1957...\n",
      "Scraping data for year 1956...\n",
      "Scraping data for year 1955...\n",
      "Scraping data for year 1954...\n",
      "Scraping data for year 1953...\n",
      "Scraping data for year 1952...\n",
      "Scraping data for year 1951...\n",
      "Scraping data for year 1950...\n",
      "Scraping data for year 1949...\n",
      "Scraping data for year 1948...\n",
      "Scraping data for year 1947...\n",
      "Scraping data for year 1946...\n",
      "Scraping data for year 1945...\n",
      "Scraping data for year 1942...\n",
      "Scraping data for year 1941...\n",
      "Scraping data for year 1940...\n",
      "Scraping data for year 1939...\n",
      "Scraping data for year 1938...\n",
      "Scraping data for year 1937...\n",
      "Scraping data for year 1936...\n",
      "Scraping data for year 1935...\n",
      "Scraping data for year 1934...\n",
      "Scraping data for year 1933...\n"
     ]
    }
   ],
   "source": [
    "# loop through each year\n",
    "\n",
    "all_games = []\n",
    "\n",
    "for link in year_links:\n",
    "    year = re.search(r'\\d{4}', link).group()  # Extract the year from the link\n",
    "    print(f\"Scraping data for year {year}...\")\n",
    "    year_url = f\"{link}\"\n",
    "\n",
    "    # Request the year's page\n",
    "    year_response = requests.get(year_url, headers=headers)\n",
    "    year_soup = BeautifulSoup(year_response.text, \"html.parser\")\n",
    "\n",
    "    # Find the \"Schedule & Game Results\" table\n",
    "    table = year_soup.find(\"table\", id=\"games\")\n",
    "    if table:\n",
    "        # Load table into a DataFrame\n",
    "        games_df = pd.read_html(str(table))[0]\n",
    "\n",
    "        # Add a column for the year\n",
    "        games_df[\"Year\"] = year\n",
    "\n",
    "        # Append to the list\n",
    "        all_games.append(games_df)\n",
    "\n",
    "    # Be polite and avoid overloading the server\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Misc_Year</th>\n",
       "      <th>Misc_Week</th>\n",
       "      <th>Misc_Day</th>\n",
       "      <th>Misc_Date</th>\n",
       "      <th>Misc_Time</th>\n",
       "      <th>Misc_Outcome</th>\n",
       "      <th>Misc_OT</th>\n",
       "      <th>Misc_Rec</th>\n",
       "      <th>Misc_Location</th>\n",
       "      <th>Misc_Opp</th>\n",
       "      <th>...</th>\n",
       "      <th>Offense_RushY</th>\n",
       "      <th>Offense_TO</th>\n",
       "      <th>Defense_1stD</th>\n",
       "      <th>Defense_TotYd</th>\n",
       "      <th>Defense_PassY</th>\n",
       "      <th>Defense_RushY</th>\n",
       "      <th>Defense_TO</th>\n",
       "      <th>Expected_Points_Offense</th>\n",
       "      <th>Expected_Points_Defense</th>\n",
       "      <th>Expected_Points_Sp_Tms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>September 8</td>\n",
       "      <td>1:00PM ET</td>\n",
       "      <td>W</td>\n",
       "      <td>N</td>\n",
       "      <td>1-0</td>\n",
       "      <td>Away</td>\n",
       "      <td>Atlanta Falcons</td>\n",
       "      <td>...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>13.70</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>Sun</td>\n",
       "      <td>September 15</td>\n",
       "      <td>4:25PM ET</td>\n",
       "      <td>W</td>\n",
       "      <td>N</td>\n",
       "      <td>2-0</td>\n",
       "      <td>Away</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>...</td>\n",
       "      <td>141.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>6.86</td>\n",
       "      <td>-1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Sun</td>\n",
       "      <td>September 22</td>\n",
       "      <td>1:00PM ET</td>\n",
       "      <td>W</td>\n",
       "      <td>N</td>\n",
       "      <td>3-0</td>\n",
       "      <td>Home</td>\n",
       "      <td>Los Angeles Chargers</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.48</td>\n",
       "      <td>6.58</td>\n",
       "      <td>-4.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Sun</td>\n",
       "      <td>September 29</td>\n",
       "      <td>1:00PM ET</td>\n",
       "      <td>L</td>\n",
       "      <td>N</td>\n",
       "      <td>3-1</td>\n",
       "      <td>Away</td>\n",
       "      <td>Indianapolis Colts</td>\n",
       "      <td>...</td>\n",
       "      <td>122.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.80</td>\n",
       "      <td>-12.91</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>Sun</td>\n",
       "      <td>October 6</td>\n",
       "      <td>8:20PM ET</td>\n",
       "      <td>L</td>\n",
       "      <td>N</td>\n",
       "      <td>3-2</td>\n",
       "      <td>Home</td>\n",
       "      <td>Dallas Cowboys</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>-11.22</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Misc_Year Misc_Week Misc_Day     Misc_Date  Misc_Time Misc_Outcome Misc_OT  \\\n",
       "0      2024         1      Sun   September 8  1:00PM ET            W       N   \n",
       "1      2024         2      Sun  September 15  4:25PM ET            W       N   \n",
       "2      2024         3      Sun  September 22  1:00PM ET            W       N   \n",
       "3      2024         4      Sun  September 29  1:00PM ET            L       N   \n",
       "4      2024         5      Sun     October 6  8:20PM ET            L       N   \n",
       "\n",
       "  Misc_Rec Misc_Location              Misc_Opp  ...  Offense_RushY  \\\n",
       "0      1-0          Away       Atlanta Falcons  ...          137.0   \n",
       "1      2-0          Away        Denver Broncos  ...          141.0   \n",
       "2      3-0          Home  Los Angeles Chargers  ...          114.0   \n",
       "3      3-1          Away    Indianapolis Colts  ...          122.0   \n",
       "4      3-2          Home        Dallas Cowboys  ...           92.0   \n",
       "\n",
       "   Offense_TO  Defense_1stD  Defense_TotYd  Defense_PassY  Defense_RushY  \\\n",
       "0         NaN          15.0          226.0          137.0           89.0   \n",
       "1         NaN          13.0          295.0          231.0           64.0   \n",
       "2         1.0          10.0          166.0          105.0           61.0   \n",
       "3         2.0          22.0          358.0          225.0          133.0   \n",
       "4         1.0          25.0          445.0          336.0          109.0   \n",
       "\n",
       "   Defense_TO  Expected_Points_Offense  Expected_Points_Defense  \\\n",
       "0         3.0                    -6.25                    13.70   \n",
       "1         2.0                    -1.20                     6.86   \n",
       "2         NaN                    10.48                     6.58   \n",
       "3         NaN                     2.80                   -12.91   \n",
       "4         3.0                     2.75                   -11.22   \n",
       "\n",
       "   Expected_Points_Sp_Tms  \n",
       "0                    2.05  \n",
       "1                   -1.25  \n",
       "2                   -4.19  \n",
       "3                    4.94  \n",
       "4                    2.98  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 3: Concatenate all dataframes into a single DataFrame\n",
    "schedule_df = pd.concat(all_games, ignore_index=True)\n",
    "\n",
    "# make a copy in case we want to go back\n",
    "schedule_df2 = schedule_df.copy()\n",
    "\n",
    "# assuming df is your DataFrame after reading the table\n",
    "# flatten the multi-level column index\n",
    "schedule_df2.columns = ['_'.join(col).strip() for col in schedule_df2.columns.values]\n",
    "\n",
    "# rename columns containing 'Unnamed' to add 'Misc_' prefix and clean the rest\n",
    "schedule_df2.columns = [\n",
    "    'Misc_' + re.sub(r'^Unnamed:.*?_level_0_', '', col) if 'Unnamed' in col else col\n",
    "    for col in schedule_df2.columns\n",
    "]\n",
    "\n",
    "# rename cols without headers on website\n",
    "schedule_df2.rename(columns={'Misc_Unnamed: 3_level_1': 'Misc_Time', 'Misc_Unnamed: 4_level_1': 'Misc_Boxscore', 'Misc_Unnamed: 8_level_1': 'Misc_Location',\n",
    "                             'Misc_Unnamed: 5_level_1': 'Misc_Outcome', 'Expected Points_Sp. Tms': 'Expected Points_Sp_Tms', 'Year_': 'Misc_Year'}, inplace=True)\n",
    "\n",
    "# remove boxscore and and fix 'Expected Points_Sp. Tms'\n",
    "\n",
    "# move year to front \n",
    "first_col = schedule_df2.pop('Misc_Year')\n",
    "# insert column using insert(position,column_name, first_column) function \n",
    "schedule_df2.insert(0, 'Misc_Year', first_col) \n",
    "\n",
    "# drop boxscore\n",
    "schedule_df3 = schedule_df2.drop('Misc_Boxscore', axis=1)\n",
    "\n",
    "# cleanup OT overtime and Home/Away\n",
    "\n",
    "# replace '@' with 'Away' and NaN with 'Home'\n",
    "schedule_df3['Misc_Location'] = schedule_df3['Misc_Location'].replace('@', 'Away').fillna('Home')\n",
    "\n",
    "# replace 'OT' with 'Y' and NaN with 'N'\n",
    "schedule_df3['Misc_OT'] = schedule_df3['Misc_OT'].replace('OT', 'Y').fillna('N')\n",
    "\n",
    "# add underscores to column headers instead of spaces\n",
    "schedule_df3.columns = [re.sub(r' ', '_', col) for col in schedule_df3.columns]\n",
    "\n",
    "schedule_df3.head()\n",
    "#schedule_df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Misc_Year                   object\n",
       "Misc_Week                   object\n",
       "Misc_Day                    object\n",
       "Misc_Date                   object\n",
       "Misc_Time                   object\n",
       "Misc_Outcome                object\n",
       "Misc_OT                     object\n",
       "Misc_Rec                    object\n",
       "Misc_Location               object\n",
       "Misc_Opp                    object\n",
       "Score_Tm                   float64\n",
       "Score_Opp                  float64\n",
       "Offense_1stD               float64\n",
       "Offense_TotYd              float64\n",
       "Offense_PassY              float64\n",
       "Offense_RushY              float64\n",
       "Offense_TO                 float64\n",
       "Defense_1stD               float64\n",
       "Defense_TotYd              float64\n",
       "Defense_PassY              float64\n",
       "Defense_RushY              float64\n",
       "Defense_TO                 float64\n",
       "Expected_Points_Offense    float64\n",
       "Expected_Points_Defense    float64\n",
       "Expected_Points_Sp_Tms     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule_df3.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load scraped data as a table to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error converting Pandas column with name: \"Misc_Week\" and datatype: \"object\" to an appropriate pyarrow datatype: Array, ListArray, or StructArray\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "Error converting Pandas column with name: \"Misc_Week\" and datatype: \"object\" to an appropriate pyarrow datatype: Array, ListArray, or StructArray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\crudek\\crudek_data_github\\venv_analytics\\lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:340\u001b[0m, in \u001b[0;36mbq_to_arrow_array\u001b[1;34m(series, bq_field)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mStructArray\u001b[38;5;241m.\u001b[39mfrom_pandas(series, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39marrow_type)\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyarrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrow_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mArrowTypeError:\n",
      "File \u001b[1;32mc:\\Users\\crudek\\crudek_data_github\\venv_analytics\\lib\\site-packages\\pyarrow\\array.pxi:1115\u001b[0m, in \u001b[0;36mpyarrow.lib.Array.from_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\crudek\\crudek_data_github\\venv_analytics\\lib\\site-packages\\pyarrow\\array.pxi:339\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\crudek\\crudek_data_github\\venv_analytics\\lib\\site-packages\\pyarrow\\array.pxi:85\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\crudek\\crudek_data_github\\venv_analytics\\lib\\site-packages\\pyarrow\\error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowTypeError\u001b[0m: Expected bytes, got a 'int' object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 29\u001b[0m\n\u001b[0;32m     12\u001b[0m job_config \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mLoadJobConfig(\n\u001b[0;32m     13\u001b[0m     schema\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     14\u001b[0m         bigquery\u001b[38;5;241m.\u001b[39mSchemaField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMisc_Year\u001b[39m\u001b[38;5;124m\"\u001b[39m, bigquery\u001b[38;5;241m.\u001b[39menums\u001b[38;5;241m.\u001b[39mSqlTypeNames\u001b[38;5;241m.\u001b[39mSTRING),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     write_disposition\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWRITE_TRUNCATE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# make API request\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_table_from_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschedule_df3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m)\u001b[49m  \n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# wait for the job to complete.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m job\u001b[38;5;241m.\u001b[39mresult()  \n",
      "File \u001b[1;32mc:\\Users\\crudek\\crudek_data_github\\venv_analytics\\lib\\site-packages\\google\\cloud\\bigquery\\client.py:2802\u001b[0m, in \u001b[0;36mClient.load_table_from_dataframe\u001b[1;34m(self, dataframe, destination, num_retries, job_id, job_id_prefix, location, project, job_config, parquet_compression, timeout)\u001b[0m\n\u001b[0;32m   2799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parquet_compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnappy\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# adjust the default value\u001b[39;00m\n\u001b[0;32m   2800\u001b[0m         parquet_compression \u001b[38;5;241m=\u001b[39m parquet_compression\u001b[38;5;241m.\u001b[39mupper()\n\u001b[1;32m-> 2802\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe_to_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2803\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_job_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtmppath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2806\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparquet_compression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparquet_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparquet_use_compliant_nested_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2808\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2810\u001b[0m     dataframe\u001b[38;5;241m.\u001b[39mto_parquet(\n\u001b[0;32m   2811\u001b[0m         tmppath,\n\u001b[0;32m   2812\u001b[0m         engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2818\u001b[0m         ),\n\u001b[0;32m   2819\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\crudek\\crudek_data_github\\venv_analytics\\lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:686\u001b[0m, in \u001b[0;36mdataframe_to_parquet\u001b[1;34m(dataframe, bq_schema, filepath, parquet_compression, parquet_use_compliant_nested_type)\u001b[0m\n\u001b[0;32m    679\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    680\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_compliant_nested_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: parquet_use_compliant_nested_type}\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _versions_helpers\u001b[38;5;241m.\u001b[39mPYARROW_VERSIONS\u001b[38;5;241m.\u001b[39muse_compliant_nested_type\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    683\u001b[0m )\n\u001b[0;32m    685\u001b[0m bq_schema \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39m_to_schema_fields(bq_schema)\n\u001b[1;32m--> 686\u001b[0m arrow_table \u001b[38;5;241m=\u001b[39m \u001b[43mdataframe_to_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbq_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m pyarrow\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mwrite_table(\n\u001b[0;32m    688\u001b[0m     arrow_table,\n\u001b[0;32m    689\u001b[0m     filepath,\n\u001b[0;32m    690\u001b[0m     compression\u001b[38;5;241m=\u001b[39mparquet_compression,\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    692\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\crudek\\crudek_data_github\\venv_analytics\\lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:629\u001b[0m, in \u001b[0;36mdataframe_to_arrow\u001b[1;34m(dataframe, bq_schema)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bq_field \u001b[38;5;129;01min\u001b[39;00m bq_schema:\n\u001b[0;32m    627\u001b[0m     arrow_names\u001b[38;5;241m.\u001b[39mappend(bq_field\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    628\u001b[0m     arrow_arrays\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 629\u001b[0m         \u001b[43mbq_to_arrow_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_column_or_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbq_field\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbq_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m     )\n\u001b[0;32m    631\u001b[0m     arrow_fields\u001b[38;5;241m.\u001b[39mappend(bq_to_arrow_field(bq_field, arrow_arrays[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtype))\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m((field \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m arrow_fields)):\n",
      "File \u001b[1;32mc:\\Users\\crudek\\crudek_data_github\\venv_analytics\\lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:344\u001b[0m, in \u001b[0;36mbq_to_arrow_array\u001b[1;34m(series, bq_field)\u001b[0m\n\u001b[0;32m    342\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mError converting Pandas column with name: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and datatype: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to an appropriate pyarrow datatype: Array, ListArray, or StructArray\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    343\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39merror(msg)\n\u001b[1;32m--> 344\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mArrowTypeError(msg)\n",
      "\u001b[1;31mArrowTypeError\u001b[0m: Error converting Pandas column with name: \"Misc_Week\" and datatype: \"object\" to an appropriate pyarrow datatype: Array, ListArray, or StructArray"
     ]
    }
   ],
   "source": [
    "# used for both BQ read/write\n",
    "\n",
    "# setting environmental variable directly in your code\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = 'bq-crudek-data.json'\n",
    "\n",
    "# initialize the BigQuery Client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# set table_id to the ID of the table to create\n",
    "table_id = 'crudek-data.practice_data.steelers_games'\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"Misc_Year\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"Misc_Week\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"Misc_Day\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"Misc_Date\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"Misc_Time\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"Misc_Outcome\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"Misc_OT\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"Misc_Rec\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"Misc_Location\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"Misc_Opp\", bigquery.enums.SqlTypeNames.STRING),\n",
    "    ],\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    ")\n",
    "\n",
    "# make API request\n",
    "job = client.load_table_from_dataframe(\n",
    "    schedule_df3, table_id, job_config=job_config\n",
    ")  \n",
    "# wait for the job to complete.\n",
    "job.result()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm with shape\n",
    "table = client.get_table(table_id)\n",
    "print(\n",
    "    \"Loaded {} rows and {} columns to {}\".format(\n",
    "        table.num_rows, len(table.schema), table_id\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
